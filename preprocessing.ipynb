{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "record1 = \"databases/record1.csv\"\n",
    "record2 = \"databases/record2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIRECTORY OF DICTIONARY**\n",
    "\n",
    "*After the following code, list_directory (which gives the directory of what each index in the list in the values of the dictionary) contains:*\n",
    "['ID NUMBER', 'OFFENSE ARREST DESC', 'OFFENSE ATTEMPT DESC', 'COUNTY COMMITTED', 'DATE OF BIRTH', 'RACE DESC', 'GENDER', 'FACILITY', 'CURRENT SENTENCE PARDONED OR COMMUTED DATE', 'SENTENCE BEGIN DATE', 'MIN TERM/YEAR', 'MIN MONTH', 'MIN DAY', 'MAX TERM/YEAR', 'MAX MONTH', 'MAX DAY', 'PAROLE ELIGIBILITY DATE', 'EARLIEST POSSIBLE RELEASE DATE', 'INST RELEASE DATE', 'INST RELEASE TYPE', 'PAROLE BOARD NEXT REVIEW DATE(MONTH&YEAR)', 'PAROLE BOARD FINAL HEARING DATE(MONTH&YEAR)', 'PAROLE BOARD STATUS', 'PAROLE DATE', 'PAROLE DISCHARGE DESC', 'SENTENCE LENGTH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removed from record 2:*\n",
    "OFFENSE MINIMUM YEAR OR TERM;\n",
    "MINIMUM MONTH;\n",
    "MINIMUM DAY;\n",
    "OFFENSE MAXIMUM YEAR OR TERM;\n",
    "MAXIMUM MONTH;\n",
    "MAXIMUM DAY;\n",
    "FELONY MSDMNR CODE;\n",
    "OFFENSE TYPE CODE;\n",
    "HABITUAL CRIME;\n",
    "OFFENSE RUN CODE;\n",
    "\n",
    "*Removed from record 1:*\n",
    "COMMITTED LAST NAME;\n",
    "FIRST NAME;\n",
    "MIDDLE NAME;\n",
    "NAME EXTENSION;\n",
    "LEGAL LAST NAME;\n",
    "FIRST NAME;\n",
    "MIDDLE NAME;\n",
    "NAME EXTENSION;\n",
    "GUN CLAUSE;\n",
    "GOOD TIME LAW;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INDEX**\n",
    "\n",
    "*From record 2*\n",
    "\n",
    "'ID NUMBER' = 0\n",
    "\n",
    "'OFFENSE ARREST DESC' = 1\n",
    "\n",
    "'OFFENSE ATTEMPT DESC' = 2\n",
    "\n",
    "'COUNTY COMMITTED' = 3\n",
    "\n",
    "\n",
    "*From record 1*\n",
    "\n",
    "'DATE OF BIRTH' = 4 **changed to year**\n",
    "\n",
    "'RACE DESC' = 5\n",
    "\n",
    "'GENDER' = 6\n",
    "\n",
    "'FACILITY' = 7\n",
    "\n",
    "'CURRENT SENTENCE PARDONED OR COMMUTED DATE' = 8 **changed to year**\n",
    "\n",
    "'SENTENCE BEGIN DATE' = 9 **changed to year**\n",
    "\n",
    "'MIN TERM/YEAR' = 10\n",
    "\n",
    "'MIN MONTH' = 11\n",
    "\n",
    "'MIN DAY' = 12\n",
    "\n",
    "'MAX TERM/YEAR' = 13\n",
    "\n",
    "'MAX MONTH' = 14\n",
    "\n",
    "'MAX DAY' = 15\n",
    "\n",
    "'PAROLE ELIGIBILITY DATE' = 16 **changed to year**\n",
    "\n",
    "'EARLIEST POSSIBLE RELEASE DATE' = 17 **changed to year**\n",
    "\n",
    "'INST RELEASE DATE' = 18 **changed to year**\n",
    "\n",
    "'INST RELEASE TYPE' = 19\n",
    "\n",
    "'PAROLE BOARD NEXT REVIEW DATE(MONTH&YEAR)' = 20\n",
    "\n",
    "'PAROLE BOARD FINAL HEARING DATE(MONTH&YEAR)' = 21\n",
    "\n",
    "'PAROLE BOARD STATUS' = 22\n",
    "\n",
    "'PAROLE DATE' = 23 **changed to year**\n",
    "\n",
    "'PAROLE DISCHARGE DESC' = 24\n",
    "\n",
    "*Our additions:*\n",
    "\n",
    "'SENTENCE LENGTH' = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {}\n",
    "list_directory = []\n",
    "file_record2 = open(record2, \"r\")\n",
    "counter = 0\n",
    "for line in file_record2:\n",
    "    # split by comma\n",
    "    line = line.split(\",\")\n",
    "    if len(line) == 14:\n",
    "        if counter == 0:\n",
    "            # strip \\ufeff and \\n\n",
    "            line[0] = line[0][1:]\n",
    "            line[-1] = line[-1][0:-1]\n",
    "            # removes indexes we don't need\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(2)\n",
    "            line.pop(2)\n",
    "            line.pop(3)\n",
    "            line.pop(3)\n",
    "            list_directory = line\n",
    "        else:\n",
    "            line[-1] = line[-1][0:-1]\n",
    "            # removes indexes we don't need\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(1)\n",
    "            line.pop(2)\n",
    "            line.pop(2)\n",
    "            line.pop(3)\n",
    "            line.pop(3)\n",
    "            # strips leading and ending whitespace:\n",
    "            for item in range(len(line)):\n",
    "                line[item] = line[item].strip()\n",
    "            # add to master dict if not in already\n",
    "            if line[0] not in master_dict:\n",
    "                master_dict[line[0]] = line\n",
    "            # if it is in already, remove the id from dict as it is a multiple offender or duplicate\n",
    "            else:\n",
    "                del master_dict[line[0]]\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48223\n"
     ]
    }
   ],
   "source": [
    "# how many left over after removing of duplicated\n",
    "print(len(master_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n",
      "worked\n"
     ]
    }
   ],
   "source": [
    "file_record1 = open(record1, \"r\")\n",
    "counter = 0\n",
    "for line in file_record1:\n",
    "    line = line.split(\",\")\n",
    "    if len(line) == 32:\n",
    "        if counter == 0:\n",
    "            # remove all unneeded, then remove \\n\n",
    "            line.pop(0)\n",
    "            line.pop(0)\n",
    "            line.pop(0)\n",
    "            line.pop(0)\n",
    "            line.pop(0)\n",
    "            line.pop(0)\n",
    "            line.pop(0)\n",
    "            line.pop(0)\n",
    "            line.pop(0)\n",
    "            line.pop(5)\n",
    "            line.pop(14)\n",
    "            line[-1] = line[-1][0:-1]\n",
    "            list_directory = list_directory + line\n",
    "            list_directory.append(\"SENTENCE LENGTH\")\n",
    "        else:\n",
    "            #print(counter)\n",
    "            line[-1] = line[-1][0:-1]\n",
    "\n",
    "            for item in range(len(line)):\n",
    "                line[item] = line[item].strip()\n",
    "\n",
    "            # we only want the ones in the dictionary (first offenders)\n",
    "            if line[0] in master_dict:\n",
    "                # remove unneeded indexes, save id\n",
    "                id_ = line.pop(0)\n",
    "                line.pop(0)\n",
    "                line.pop(0)\n",
    "                line.pop(0)\n",
    "                line.pop(0)\n",
    "                line.pop(0)\n",
    "                line.pop(0)\n",
    "                line.pop(0)\n",
    "                line.pop(0)\n",
    "                line.pop(5)\n",
    "                line.pop(14)\n",
    "\n",
    "                # see if person has earliest possible release date (13) and sentence begin date (5)\n",
    "                if line[13] == '' or line[5] == '' or line[13] == ' ' or line[5] == ' ':\n",
    "                    # remove from dictionary if they don't\n",
    "                    del master_dict[id_]\n",
    "\n",
    "                else:\n",
    "                    # change DOB to year\n",
    "                    if line[0] != '':\n",
    "                        line[0] = line[0][-4:]\n",
    "                    # change sentence pardoned to year\n",
    "                    if line[4] != '':\n",
    "                        line[4] = line[4][-4:]\n",
    "                    # change sentence begin date to year\n",
    "                    if line[5] != '':\n",
    "                        line[5] = line[5][-4:]\n",
    "                    # change parol eligibility date to year\n",
    "                    if line[12] != '':\n",
    "                        line[12] = line[12][-4:]\n",
    "                    # change earliest possible release date to year\n",
    "                    if line[13] != '':\n",
    "                        line[13] = line[13][-4:]\n",
    "                        #print(line[13])\n",
    "                    # change inst release date to year\n",
    "                    if line[14] != '':\n",
    "                        line[14] = line[14][-4:]\n",
    "                    # changed parole date to year\n",
    "                    if line[19] != '' and line[19][0:7] != \"PAROLED\":\n",
    "                        line[19] = line[19][-4:]\n",
    "\n",
    "                    # add sentence length\n",
    "                    if line[13] == 'LFE' or line[13] == 'DTH':\n",
    "                        line.append(line[13])\n",
    "                    elif line[5] == 'EARM':\n",
    "                        line.append(line[5])\n",
    "                    else:\n",
    "                        sent_length = int(line[13]) - int(line[5])\n",
    "                        line.append(str(sent_length))\n",
    "\n",
    "                    master_dict[id_] = master_dict[id_] + line\n",
    "                    print(master_dict[id_][-1])\n",
    "\n",
    "    else:\n",
    "        if line[0] in master_dict:\n",
    "            print(\"worked\")\n",
    "            del master_dict[line[0]]         \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID NUMBER', 'OFFENSE ARREST DESC', 'OFFENSE ATTEMPT DESC', 'COUNTY COMMITTED', 'DATE OF BIRTH', 'RACE DESC', 'GENDER', 'FACILITY', 'CURRENT SENTENCE PARDONED OR COMMUTED DATE', 'SENTENCE BEGIN DATE', 'MIN TERM/YEAR', 'MIN MONTH', 'MIN DAY', 'MAX TERM/YEAR', 'MAX MONTH', 'MAX DAY', 'PAROLE ELIGIBILITY DATE', 'EARLIEST POSSIBLE RELEASE DATE', 'INST RELEASE DATE', 'INST RELEASE TYPE', 'PAROLE BOARD NEXT REVIEW DATE(MONTH&YEAR)', 'PAROLE BOARD FINAL HEARING DATE(MONTH&YEAR)', 'PAROLE BOARD STATUS', 'PAROLE DATE', 'PAROLE DISCHARGE DESC', 'SENTENCE LENGTH']\n"
     ]
    }
   ],
   "source": [
    "print(list_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(list_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46303\n"
     ]
    }
   ],
   "source": [
    "print(len(master_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
